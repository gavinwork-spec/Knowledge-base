#!/usr/bin/env python3
"""
æ•°æ®åº“æ€§èƒ½åˆ†æå’Œç´¢å¼•ä¼˜åŒ–è„šæœ¬
åˆ†ææŸ¥è¯¢æ€§èƒ½ï¼Œæä¾›ç´¢å¼•å»ºè®®
"""

import sqlite3
import time
import json
from pathlib import Path
from typing import List, Dict, Tuple, Any
import logging

class DatabaseOptimizer:
    """æ•°æ®åº“ä¼˜åŒ–å™¨"""

    def __init__(self, db_path: str = "./data/db.sqlite"):
        self.db_path = db_path
        self.conn = sqlite3.connect(db_path)
        self.setup_logging()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger('DatabaseOptimizer')

    def analyze_table_sizes(self) -> Dict[str, int]:
        """åˆ†æè¡¨å¤§å°"""
        self.logger.info("ğŸ“Š åˆ†æè¡¨å¤§å°...")

        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT name, sql FROM sqlite_master
            WHERE type='table' AND name NOT LIKE 'sqlite_%'
        """)

        tables = cursor.fetchall()
        table_sizes = {}

        for table_name, create_sql in tables:
            cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
            count = cursor.fetchone()[0]
            table_sizes[table_name] = count

        return table_sizes

    def get_existing_indexes(self) -> List[Dict[str, Any]]:
        """è·å–ç°æœ‰ç´¢å¼•ä¿¡æ¯"""
        self.logger.info("ğŸ“‹ è·å–ç°æœ‰ç´¢å¼•ä¿¡æ¯...")

        cursor = self.conn.cursor()
        cursor.execute("""
            SELECT name, tbl_name, sql FROM sqlite_master
            WHERE type='index' AND name NOT LIKE 'sqlite_%'
        """)

        indexes = []
        for index_name, table_name, sql in cursor.fetchall():
            indexes.append({
                'name': index_name,
                'table': table_name,
                'sql': sql,
                'is_unique': 'UNIQUE' in (sql or '').upper()
            })

        return indexes

    def analyze_query_performance(self) -> Dict[str, Any]:
        """åˆ†æå¸¸ç”¨æŸ¥è¯¢æ€§èƒ½"""
        self.logger.info("âš¡ åˆ†ææŸ¥è¯¢æ€§èƒ½...")

        cursor = self.conn.cursor()

        # å®šä¹‰å¸¸ç”¨æŸ¥è¯¢
        common_queries = [
            {
                'name': 'å®¢æˆ·æŒ‰é‚®ç®±æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM customers WHERE contact_email = ?',
                'params': ['test@example.com']
            },
            {
                'name': 'å®¢æˆ·æŒ‰å…¬å¸åæŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM customers WHERE company_name = ?',
                'params': ['Test Company']
            },
            {
                'name': 'å®¢æˆ·é‚®ç®±+å…¬å¸åæŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM customers WHERE company_name = ? AND contact_email = ?',
                'params': ['Test Company', 'test@example.com']
            },
            {
                'name': 'å›¾çº¸æŒ‰å®¢æˆ·æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM drawings WHERE customer_id = ?',
                'params': [1]
            },
            {
                'name': 'å›¾çº¸æŒ‰åˆ†ç±»æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM drawings WHERE product_category = ?',
                'params': ['èºæ “']
            },
            {
                'name': 'å›¾çº¸å®¢æˆ·+åˆ†ç±»æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM drawings WHERE customer_id = ? AND product_category = ?',
                'params': [1, 'èºæ “']
            },
            {
                'name': 'æŠ¥ä»·æŒ‰å·¥å‚æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM factory_quotes WHERE factory_id = ?',
                'params': [1]
            },
            {
                'name': 'è§„æ ¼æŒ‰åˆ†ç±»æŸ¥è¯¢',
                'query': 'EXPLAIN QUERY PLAN SELECT * FROM specifications WHERE product_category = ?',
                'params': ['èºæ “']
            }
        ]

        query_analysis = {}

        for query_info in common_queries:
            try:
                # æ‰§è¡ŒæŸ¥è¯¢è®¡åˆ’åˆ†æ
                cursor.execute(query_info['query'], query_info['params'])
                explain_results = cursor.fetchall()

                # åˆ†ææŸ¥è¯¢è®¡åˆ’
                uses_index = any('USING INDEX' in str(row) for row in explain_results)
                scan_type = 'INDEX SCAN' if uses_index else 'TABLE SCAN'

                query_analysis[query_info['name']] = {
                    'query': query_info['query'].replace('EXPLAIN QUERY PLAN ', ''),
                    'uses_index': uses_index,
                    'scan_type': scan_type,
                    'explain_plan': [str(row) for row in explain_results]
                }

            except Exception as e:
                self.logger.warning(f"æŸ¥è¯¢åˆ†æå¤±è´¥ {query_info['name']}: {e}")
                query_analysis[query_info['name']] = {
                    'error': str(e)
                }

        return query_analysis

    def test_query_performance(self) -> Dict[str, float]:
        """æµ‹è¯•å®é™…æŸ¥è¯¢æ€§èƒ½"""
        self.logger.info("â±ï¸ æµ‹è¯•æŸ¥è¯¢æ€§èƒ½...")

        cursor = self.conn.cursor()

        # æ€§èƒ½æµ‹è¯•æŸ¥è¯¢
        performance_queries = [
            {
                'name': 'å®¢æˆ·æ€»æ•°æŸ¥è¯¢',
                'query': 'SELECT COUNT(*) FROM customers'
            },
            {
                'name': 'å›¾çº¸æ€»æ•°æŸ¥è¯¢',
                'query': 'SELECT COUNT(*) FROM drawings'
            },
            {
                'name': 'å®¢æˆ·å›¾çº¸å…³è”æŸ¥è¯¢',
                'query': '''
                    SELECT c.company_name, COUNT(d.id) as drawing_count
                    FROM customers c
                    LEFT JOIN drawings d ON c.id = d.customer_id
                    GROUP BY c.id
                '''
            },
            {
                'name': 'åˆ†ç±»ç»Ÿè®¡æŸ¥è¯¢',
                'query': '''
                    SELECT product_category, COUNT(*) as count
                    FROM drawings
                    WHERE product_category IS NOT NULL
                    GROUP BY product_category
                '''
            }
        ]

        performance_results = {}

        for query_info in performance_queries:
            try:
                # å¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
                times = []
                for _ in range(5):
                    start_time = time.time()
                    cursor.execute(query_info['query'])
                    cursor.fetchall()
                    end_time = time.time()
                    times.append(end_time - start_time)

                avg_time = sum(times) / len(times)
                performance_results[query_info['name']] = {
                    'average_time': avg_time,
                    'min_time': min(times),
                    'max_time': max(times),
                    'query': query_info['query']
                }

            except Exception as e:
                self.logger.warning(f"æ€§èƒ½æµ‹è¯•å¤±è´¥ {query_info['name']}: {e}")
                performance_results[query_info['name']] = {'error': str(e)}

        return performance_results

    def recommend_indexes(self, table_sizes: Dict[str, int], query_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """æ¨èç´¢å¼•"""
        self.logger.info("ğŸ’¡ ç”Ÿæˆç´¢å¼•å»ºè®®...")

        recommendations = []

        # åˆ†æå®¢æˆ·è¡¨
        if table_sizes.get('customers', 0) > 10:
            # æ£€æŸ¥æ˜¯å¦æœ‰é‚®ç®±+å…¬å¸åå¤åˆç´¢å¼•
            cursor = self.conn.cursor()
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND sql LIKE '%company_name%' AND sql LIKE '%contact_email%'
            """)
            compound_index = cursor.fetchone()

            if not compound_index:
                recommendations.append({
                    'table': 'customers',
                    'columns': ['company_name', 'contact_email'],
                    'type': 'composite',
                    'reason': 'æ ¸å¿ƒå®¢æˆ·æ ‡è¯†æŸ¥è¯¢ä¼˜åŒ–',
                    'priority': 'high',
                    'sql': 'CREATE INDEX idx_customers_company_email_compound ON customers(company_name, contact_email)'
                })

        # åˆ†æå›¾çº¸è¡¨
        if table_sizes.get('drawings', 0) > 100:
            # æ£€æŸ¥å®¢æˆ·+åˆ†ç±»å¤åˆç´¢å¼•
            cursor = self.conn.cursor()
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND sql LIKE '%customer_id%' AND sql LIKE '%product_category%'
            """)
            compound_index = cursor.fetchone()

            if not compound_index:
                recommendations.append({
                    'table': 'drawings',
                    'columns': ['customer_id', 'product_category'],
                    'type': 'composite',
                    'reason': 'å®¢æˆ·äº§å“åˆ†ç±»æŸ¥è¯¢ä¼˜åŒ–',
                    'priority': 'medium',
                    'sql': 'CREATE INDEX idx_drawings_customer_category_compound ON drawings(customer_id, product_category)'
                })

            # ä¸Šä¼ æ—¥æœŸç´¢å¼•ï¼ˆç”¨äºæ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼‰
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND tbl_name='drawings' AND sql LIKE '%upload_date%'
            """)
            date_index = cursor.fetchone()

            if not date_index:
                recommendations.append({
                    'table': 'drawings',
                    'columns': ['upload_date'],
                    'type': 'single',
                    'reason': 'æ—¶é—´èŒƒå›´æŸ¥è¯¢ä¼˜åŒ–',
                    'priority': 'low',
                    'sql': 'CREATE INDEX idx_drawings_upload_date_optimized ON drawings(upload_date)'
                })

        # åˆ†ææŠ¥ä»·è¡¨
        if table_sizes.get('factory_quotes', 0) > 50:
            # å·¥å‚+æ—¥æœŸå¤åˆç´¢å¼•
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND sql LIKE '%factory_id%' AND sql LIKE '%quote_date%'
            """)
            compound_index = cursor.fetchone()

            if not compound_index:
                recommendations.append({
                    'table': 'factory_quotes',
                    'columns': ['factory_id', 'quote_date'],
                    'type': 'composite',
                    'reason': 'å·¥å‚æŠ¥ä»·å†å²æŸ¥è¯¢ä¼˜åŒ–',
                    'priority': 'medium',
                    'sql': 'CREATE INDEX idx_quotes_factory_date_compound ON factory_quotes(factory_id, quote_date)'
                })

        # æ£€æŸ¥å…¨è¡¨æ‰«æçš„æŸ¥è¯¢
        for query_name, analysis in query_analysis.items():
            if analysis.get('uses_index') == False:
                if 'customers' in query_name:
                    recommendations.append({
                        'table': 'customers',
                        'columns': self._extract_columns_from_query(analysis.get('query', '')),
                        'type': 'derived',
                        'reason': f'ä¼˜åŒ–æŸ¥è¯¢: {query_name}',
                        'priority': 'high',
                        'sql': f'-- éœ€è¦åŸºäºæŸ¥è¯¢åˆ†æ: {analysis.get("query", "")}'
                    })

        return recommendations

    def _extract_columns_from_query(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–WHEREå­å¥çš„åˆ—"""
        # ç®€å•çš„åˆ—æå–é€»è¾‘
        if 'WHERE' in query.upper():
            where_clause = query.upper().split('WHERE')[1]
            columns = []
            for part in where_clause.split('AND'):
                if '=' in part:
                    column = part.split('=')[0].strip()
                    columns.append(column)
            return columns
        return []

    def create_recommended_indexes(self, recommendations: List[Dict[str, Any]], dry_run: bool = True) -> Dict[str, Any]:
        """åˆ›å»ºæ¨èçš„ç´¢å¼•"""
        self.logger.info(f"ğŸ”§ {'æ¨¡æ‹Ÿ' if dry_run else 'æ‰§è¡Œ'}ç´¢å¼•åˆ›å»º...")

        results = {
            'created': [],
            'failed': [],
            'skipped': []
        }

        cursor = self.conn.cursor()

        for rec in recommendations:
            if rec.get('sql') and not rec.get('sql', '').startswith('--'):
                try:
                    if not dry_run:
                        cursor.execute(rec['sql'])
                        self.conn.commit()
                        self.logger.info(f"âœ… åˆ›å»ºç´¢å¼•: {rec['sql']}")
                        results['created'].append(rec)
                    else:
                        self.logger.info(f"ğŸ” æ¨¡æ‹Ÿåˆ›å»º: {rec['sql']}")
                        results['created'].append(rec)

                except Exception as e:
                    self.logger.error(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {rec['sql']} - {e}")
                    results['failed'].append({**rec, 'error': str(e)})
            else:
                results['skipped'].append(rec)

        return results

    def analyze_database_stats(self) -> Dict[str, Any]:
        """åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        self.logger.info("ğŸ“ˆ åˆ†ææ•°æ®åº“ç»Ÿè®¡...")

        cursor = self.conn.cursor()

        stats = {
            'database_size': self._get_database_size(),
            'table_stats': self.analyze_table_sizes(),
            'index_count': len(self.get_existing_indexes()),
            'page_size': self._get_page_size(),
            'cache_size': self._get_cache_size()
        }

        return stats

    def _get_database_size(self) -> int:
        """è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°"""
        try:
            return Path(self.db_path).stat().st_size
        except:
            return 0

    def _get_page_size(self) -> int:
        """è·å–æ•°æ®åº“é¡µé¢å¤§å°"""
        cursor = self.conn.cursor()
        cursor.execute("PRAGMA page_size")
        return cursor.fetchone()[0]

    def _get_cache_size(self) -> int:
        """è·å–ç¼“å­˜å¤§å°"""
        cursor = self.conn.cursor()
        cursor.execute("PRAGMA cache_size")
        return cursor.fetchone()[0]

    def generate_optimization_report(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        self.logger.info("ğŸ“„ ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š...")

        # æ”¶é›†æ‰€æœ‰åˆ†ææ•°æ®
        table_sizes = self.analyze_table_sizes()
        existing_indexes = self.get_existing_indexes()
        query_analysis = self.analyze_query_performance()
        performance_tests = self.test_query_performance()
        recommendations = self.recommend_indexes(table_sizes, query_analysis)
        db_stats = self.analyze_database_stats()

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'generated_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'database_path': self.db_path,
            'database_stats': db_stats,
            'table_sizes': table_sizes,
            'existing_indexes': existing_indexes,
            'query_analysis': query_analysis,
            'performance_tests': performance_tests,
            'recommendations': recommendations,
            'summary': {
                'total_tables': len(table_sizes),
                'total_indexes': len(existing_indexes),
                'total_recommendations': len(recommendations),
                'high_priority_recommendations': len([r for r in recommendations if r.get('priority') == 'high']),
                'medium_priority_recommendations': len([r for r in recommendations if r.get('priority') == 'medium']),
                'low_priority_recommendations': len([r for r in recommendations if r.get('priority') == 'low'])
            }
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = f"./reports/database_optimization_{time.strftime('%Y%m%d_%H%M%S')}.json"
        Path("./reports").mkdir(exist_ok=True)

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        self.logger.info(f"ğŸ“„ ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        # ç”Ÿæˆç®€è¦æ–‡æœ¬æŠ¥å‘Š
        text_report = self._generate_text_report(report)
        text_report_file = f"./reports/database_optimization_summary_{time.strftime('%Y%m%d_%H%M%S')}.txt"

        with open(text_report_file, 'w', encoding='utf-8') as f:
            f.write(text_report)

        return report_file

    def _generate_text_report(self, report: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        text = f"""
æ•°æ®åº“ä¼˜åŒ–æŠ¥å‘Š
{'=' * 50}
ç”Ÿæˆæ—¶é—´: {report['generated_at']}
æ•°æ®åº“è·¯å¾„: {report['database_path']}

ğŸ“Š æ•°æ®åº“ç»Ÿè®¡:
- æ•°æ®åº“å¤§å°: {report['database_stats']['database_size'] / 1024:.1f} KB
- è¡¨æ•°é‡: {report['summary']['total_tables']}
- ç´¢å¼•æ•°é‡: {report['summary']['total_indexes']}
- é¡µé¢å¤§å°: {report['database_stats']['page_size']} bytes

ğŸ“‹ è¡¨å¤§å°ç»Ÿè®¡:
"""
        for table, count in report['table_sizes'].items():
            text += f"- {table}: {count} æ¡è®°å½•\n"

        text += f"""
âš¡ æŸ¥è¯¢æ€§èƒ½åˆ†æ:
"""
        for query_name, analysis in report['query_analysis'].items():
            status = "âœ…" if analysis.get('uses_index') else "âŒ"
            text += f"- {status} {query_name}: {analysis.get('scan_type', 'Unknown')}\n"

        text += f"""
ğŸ’¡ ç´¢å¼•å»ºè®®:
- é«˜ä¼˜å…ˆçº§: {report['summary']['high_priority_recommendations']} ä¸ª
- ä¸­ä¼˜å…ˆçº§: {report['summary']['medium_priority_recommendations']} ä¸ª
- ä½ä¼˜å…ˆçº§: {report['summary']['low_priority_recommendations']} ä¸ª

è¯¦ç»†å»ºè®®:
"""
        for rec in report['recommendations']:
            priority_icon = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(rec.get('priority'), "âšª")
            text += f"- {priority_icon} {rec.get('table', '')}.{','.join(rec.get('columns', []))}: {rec.get('reason', '')}\n"

        return text

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.conn.close()

def main():
    """ä¸»å‡½æ•°"""
    optimizer = DatabaseOptimizer()

    try:
        # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
        report_file = optimizer.generate_optimization_report()

        # è·å–æ¨èç´¢å¼•
        table_sizes = optimizer.analyze_table_sizes()
        query_analysis = optimizer.analyze_query_performance()
        recommendations = optimizer.recommend_indexes(table_sizes, query_analysis)

        print(f"\nğŸ¯ æ•°æ®åº“ä¼˜åŒ–å®Œæˆ!")
        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print(f"ğŸ’¡ ç´¢å¼•å»ºè®®: {len(recommendations)} ä¸ª")

        if recommendations:
            print("\nğŸ” æ¨¡æ‹Ÿåˆ›å»ºç´¢å¼•...")
            results = optimizer.create_recommended_indexes(recommendations, dry_run=True)
            print(f"âœ… å¯åˆ›å»º: {len(results['created'])} ä¸ª")
            print(f"âŒ å¤±è´¥: {len(results['failed'])} ä¸ª")
            print(f"â­ï¸ è·³è¿‡: {len(results['skipped'])} ä¸ª")

    finally:
        optimizer.close()

if __name__ == "__main__":
    main()