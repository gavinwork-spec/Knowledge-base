#!/usr/bin/env python3
"""
ç›‘æ§æŒ‡æ ‡æ”¶é›†è„šæœ¬
æ”¶é›†å’Œè®¡ç®—çŸ¥è¯†åº“ç³»ç»Ÿçš„å„é¡¹KPIæŒ‡æ ‡
"""

import os
import sys
import json
import sqlite3
import logging
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Tuple, Optional
from pathlib import Path
import statistics

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("MetricsCollector")

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self, db_path: str = "knowledge_base.db"):
        self.db_path = db_path
        self.conn = None
        self.current_metrics = {}
        self.historical_metrics = []
        self.thresholds = {
            "knowledge_growth_rate_min": 0.05,  # 5%å‘¨å¢é•¿ç‡
            "search_success_rate_min": 0.70,  # 70%æœç´¢æˆåŠŸç‡
            "recommendation_acceptance_rate_min": 0.30,  # 30%æ¨èé‡‡çº³ç‡
            "avg_query_time_max": 2.0,  # 2ç§’æœ€å¤§å“åº”æ—¶é—´
            "system_availability_min": 0.95  # 95%ç³»ç»Ÿå¯ç”¨æ€§
        }

    def connect_database(self) -> bool:
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self.conn.row_factory = sqlite3.Row
            logger.info(f"Connected to database: {self.db_path}")
            return True
        except Exception as e:
            logger.error(f"Failed to connect to database: {e}")
            return False

    def calculate_knowledge_growth_metrics(self) -> Dict:
        """è®¡ç®—çŸ¥è¯†å¢é•¿æŒ‡æ ‡"""
        try:
            cursor = self.conn.cursor()

            # è®¡ç®—æ€»çŸ¥è¯†æ¡ç›®æ•°
            cursor.execute("SELECT COUNT(*) as total FROM knowledge_entries")
            total_entries = cursor.fetchone()['total']

            # è®¡ç®—å‘¨å¢é•¿æ•°
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            cursor.execute("""
                SELECT COUNT(*) as week_count
                FROM knowledge_entries
                WHERE created_at > ?
            """, (week_ago,))
            week_entries = cursor.fetchone()['week_count']

            # è®¡ç®—æœˆå¢é•¿æ•°
            month_ago = (datetime.now() - timedelta(days=30)).isoformat()
            cursor.execute("""
                SELECT COUNT(*) as month_count
                FROM knowledge_entries
                WHERE created_at > ?
            """, (month_ago,))
            month_entries = cursor.fetchone()['month_count']

            # è®¡ç®—å¢é•¿ç‡
            week_ago_total = total_entries - week_entries
            month_ago_total = total_entries - month_entries

            week_growth_rate = week_entries / max(week_ago_total, 1) * 100
            month_growth_rate = month_entries / max(month_ago_total, 1) * 100

            # æŒ‰å®ä½“ç±»å‹ç»Ÿè®¡
            cursor.execute("""
                SELECT entity_type, COUNT(*) as count
                FROM knowledge_entries
                GROUP BY entity_type
                ORDER BY count DESC
            """)
            entity_distribution = {row['entity_type']: row['count'] for row in cursor.fetchall()}

            metrics = {
                "total_entries": total_entries,
                "week_growth_count": week_entries,
                "month_growth_count": month_entries,
                "week_growth_rate": round(week_growth_rate, 2),
                "month_growth_rate": round(month_growth_rate, 2),
                "entity_distribution": entity_distribution,
                "growth_status": "healthy" if week_growth_rate >= self.thresholds["knowledge_growth_rate_min"] * 100 else "warning"
            }

            logger.info(f"Knowledge growth metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate knowledge growth metrics: {e}")
            return {}

    def calculate_search_performance_metrics(self) -> Dict:
        """è®¡ç®—æœç´¢æ€§èƒ½æŒ‡æ ‡"""
        try:
            cursor = self.conn.cursor()

            # å¦‚æœæœ‰æœç´¢æ—¥å¿—è¡¨ï¼Œä»ä¸­è¯»å–æ•°æ®
            # è¿™é‡Œæ¨¡æ‹Ÿæœç´¢æ€§èƒ½æ•°æ®
            # å®é™…åº”è¯¥ä»æœç´¢æ—¥å¿—ä¸­ç»Ÿè®¡

            # æ¨¡æ‹Ÿæ•°æ®ï¼ˆå®é™…åº”è¯¥ä»æ—¥å¿—ç»Ÿè®¡ï¼‰
            total_searches = 150
            successful_searches = 125
            avg_response_time = 1.2
            no_result_searches = 25

            search_success_rate = successful_searches / total_searches * 100
            no_result_rate = no_result_searches / total_searches * 100

            metrics = {
                "total_searches": total_searches,
                "successful_searches": successful_searches,
                "search_success_rate": round(search_success_rate, 2),
                "avg_response_time": round(avg_response_time, 3),
                "no_result_rate": round(no_result_rate, 2),
                "search_status": "healthy" if search_success_rate >= self.thresholds["search_success_rate_min"] * 100 else "warning"
            }

            logger.info(f"Search performance metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate search performance metrics: {e}")
            return {}

    def calculate_recommendation_metrics(self) -> Dict:
        """è®¡ç®—æ¨èç³»ç»ŸæŒ‡æ ‡"""
        try:
            cursor = self.conn.cursor()

            # æ£€æŸ¥æ¨èè¡¨æ˜¯å¦å­˜åœ¨
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='table' AND name='recommendations'
            """)
            if not cursor.fetchone():
                return {"status": "no_recommendation_data"}

            # è®¡ç®—æ¨èæŒ‡æ ‡
            cursor.execute("SELECT COUNT(*) as total FROM recommendations")
            total_recommendations = cursor.fetchone()['total']

            # è®¡ç®—æœ¬å‘¨æ¨èæ•°
            week_ago = (datetime.now() - timedelta(days=7)).isoformat()
            cursor.execute("""
                SELECT COUNT(*) as week_count
                FROM recommendations
                WHERE created_at > ?
            """, (week_ago,))
            week_recommendations = cursor.fetchone()['week_count']

            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            cursor.execute("SELECT AVG(confidence_score) as avg_confidence FROM recommendations")
            avg_confidence = cursor.fetchone()['avg_confidence'] or 0

            # è®¡ç®—æ¨èç±»å‹åˆ†å¸ƒ
            cursor.execute("""
                SELECT recommendation_type, COUNT(*) as count
                FROM recommendations
                GROUP BY recommendation_type
            """)
            type_distribution = {row['recommendation_type']: row['count'] for row in cursor.fetchall()}

            # æ¨¡æ‹Ÿæ¨èé‡‡çº³ç‡ï¼ˆå®é™…åº”è¯¥ä»ç”¨æˆ·åé¦ˆä¸­ç»Ÿè®¡ï¼‰
            recommendation_acceptance_rate = 35.5  # æ¨¡æ‹Ÿæ•°æ®

            metrics = {
                "total_recommendations": total_recommendations,
                "week_recommendations": week_recommendations,
                "avg_confidence_score": round(avg_confidence * 100, 2),
                "recommendation_acceptance_rate": recommendation_acceptance_rate,
                "type_distribution": type_distribution,
                "recommendation_status": "healthy" if recommendation_acceptance_rate >= self.thresholds["recommendation_acceptance_rate_min"] * 100 else "warning"
            }

            logger.info(f"Recommendation metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate recommendation metrics: {e}")
            return {}

    def calculate_system_health_metrics(self) -> Dict:
        """è®¡ç®—ç³»ç»Ÿå¥åº·æŒ‡æ ‡"""
        try:
            # æ£€æŸ¥æ•°æ®åº“è¿æ¥
            db_health = self.conn is not None

            # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶å¤§å°
            db_size = 0
            if os.path.exists(self.db_path):
                db_size = os.path.getsize(self.db_path) / (1024 * 1024)  # MB

            # æ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
            cursor = self.conn.cursor()
            cursor.execute("PRAGMA integrity_check")
            integrity_result = cursor.fetchone()[0]

            # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND name NOT LIKE 'sqlite_%'
            """)
            index_count = len(cursor.fetchall())

            # è®¡ç®—ç³»ç»Ÿå¯ç”¨æ€§ï¼ˆåŸºäºæœ€è¿‘çš„é”™è¯¯æ—¥å¿—ï¼‰
            # è¿™é‡Œç®€åŒ–å¤„ç†
            system_availability = 98.5  # æ¨¡æ‹Ÿæ•°æ®

            metrics = {
                "database_connected": db_health,
                "database_size_mb": round(db_size, 2),
                "integrity_check": integrity_result,
                "index_count": index_count,
                "system_availability": system_availability,
                "system_status": "healthy" if system_availability >= self.thresholds["system_availability_min"] * 100 else "warning"
            }

            logger.info(f"System health metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate system health metrics: {e}")
            return {}

    def calculate_user_engagement_metrics(self) -> Dict:
        """è®¡ç®—ç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡"""
        try:
            # è¿™é‡Œæ¨¡æ‹Ÿç”¨æˆ·å‚ä¸åº¦æ•°æ®
            # å®é™…åº”è¯¥ä»ç”¨æˆ·æ´»åŠ¨æ—¥å¿—ä¸­ç»Ÿè®¡

            metrics = {
                "active_users_today": 8,
                "active_users_week": 25,
                "avg_session_duration": 15.5,  # åˆ†é’Ÿ
                "page_views_today": 156,
                "queries_per_user": 12.3,
                "repeat_user_rate": 68.5,  # ç™¾åˆ†æ¯”
                "engagement_status": "healthy"
            }

            logger.info(f"User engagement metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate user engagement metrics: {e}")
            return {}

    def calculate_api_performance_metrics(self) -> Dict:
        """è®¡ç®—APIæ€§èƒ½æŒ‡æ ‡"""
        try:
            # è¿™é‡Œæ¨¡æ‹ŸAPIæ€§èƒ½æ•°æ®
            # å®é™…åº”è¯¥ä»APIè®¿é—®æ—¥å¿—ä¸­ç»Ÿè®¡

            endpoints = {
                "/api/knowledge/entries": {"requests": 450, "avg_time": 0.15, "error_rate": 0.02},
                "/api/knowledge/search": {"requests": 280, "avg_time": 0.45, "error_rate": 0.05},
                "/api/v1/chat/query": {"requests": 120, "avg_time": 1.2, "error_rate": 0.08},
                "/api/health": {"requests": 60, "avg_time": 0.05, "error_rate": 0.00}
            }

            total_requests = sum(ep["requests"] for ep in endpoints.values())
            avg_response_time = sum(ep["avg_time"] * ep["requests"] for ep in endpoints.values()) / total_requests
            overall_error_rate = sum(ep["error_rate"] * ep["requests"] for ep in endpoints.values()) / total_requests

            metrics = {
                "total_requests": total_requests,
                "avg_response_time": round(avg_response_time, 3),
                "overall_error_rate": round(overall_error_rate * 100, 2),
                "endpoints": endpoints,
                "api_status": "healthy" if avg_response_time <= self.thresholds["avg_query_time_max"] else "warning"
            }

            logger.info(f"API performance metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate API performance metrics: {e}")
            return {}

    def calculate_business_impact_metrics(self) -> Dict:
        """è®¡ç®—ä¸šåŠ¡å½±å“æŒ‡æ ‡"""
        try:
            # è¿™é‡Œæ¨¡æ‹Ÿä¸šåŠ¡å½±å“æ•°æ®
            # å®é™…åº”è¯¥ä»ä¸šåŠ¡æ•°æ®ä¸­è®¡ç®—

            metrics = {
                "time_saved_hours_per_week": 12.5,  # æ¯å‘¨èŠ‚çœçš„æ—¶é—´
                "productivity_improvement": 35.8,  # ç”Ÿäº§åŠ›æå‡ç™¾åˆ†æ¯”
                "cost_reduction_per_month": 2500,  # æ¯æœˆèŠ‚çœçš„æˆæœ¬
                "decision_speed_improvement": 45.2,  # å†³ç­–é€Ÿåº¦æå‡ç™¾åˆ†æ¯”
                "knowledge_reuse_rate": 78.5,  # çŸ¥è¯†å¤ç”¨ç‡
                "business_value_status": "excellent"
            }

            logger.info(f"Business impact metrics: {metrics}")
            return metrics

        except Exception as e:
            logger.error(f"Failed to calculate business impact metrics: {e}")
            return {}

    def collect_all_metrics(self) -> Dict:
        """æ”¶é›†æ‰€æœ‰æŒ‡æ ‡"""
        try:
            logger.info("Collecting all metrics...")

            # æ”¶é›†å„ç±»æŒ‡æ ‡
            self.current_metrics = {
                "collection_time": datetime.now().isoformat(),
                "knowledge_growth": self.calculate_knowledge_growth_metrics(),
                "search_performance": self.calculate_search_performance_metrics(),
                "recommendations": self.calculate_recommendation_metrics(),
                "system_health": self.calculate_system_health_metrics(),
                "user_engagement": self.calculate_user_engagement_metrics(),
                "api_performance": self.calculate_api_performance_metrics(),
                "business_impact": self.calculate_business_impact_metrics()
            }

            # è®¡ç®—æ€»ä½“å¥åº·è¯„åˆ†
            health_scores = []
            for category, metrics in self.current_metrics.items():
                if isinstance(metrics, dict) and "status" in metrics:
                    if metrics["status"] == "healthy":
                        health_scores.append(100)
                    elif metrics["status"] == "warning":
                        health_scores.append(70)
                    else:
                        health_scores.append(30)

            overall_health_score = statistics.mean(health_scores) if health_scores else 0

            self.current_metrics["overall_health_score"] = round(overall_health_score, 2)
            self.current_metrics["overall_status"] = (
                "excellent" if overall_health_score >= 90 else
                "good" if overall_health_score >= 75 else
                "fair" if overall_health_score >= 60 else "poor"
            )

            # æ£€æŸ¥é˜ˆå€¼å‘Šè­¦
            alerts = self.check_threshold_alerts()
            self.current_metrics["alerts"] = alerts

            logger.info(f"Metrics collection completed. Overall health score: {overall_health_score:.2f}")
            return self.current_metrics

        except Exception as e:
            logger.error(f"Failed to collect all metrics: {e}")
            return {}

    def check_threshold_alerts(self) -> List[Dict]:
        """æ£€æŸ¥é˜ˆå€¼å‘Šè­¦"""
        alerts = []

        try:
            # æ£€æŸ¥çŸ¥è¯†å¢é•¿ç‡
            if "knowledge_growth" in self.current_metrics:
                growth_rate = self.current_metrics["knowledge_growth"].get("week_growth_rate", 0)
                if growth_rate < self.thresholds["knowledge_growth_rate_min"] * 100:
                    alerts.append({
                        "type": "warning",
                        "metric": "knowledge_growth_rate",
                        "current_value": growth_rate,
                        "threshold": self.thresholds["knowledge_growth_rate_min"] * 100,
                        "message": f"çŸ¥è¯†å¢é•¿ç‡ä½äºé˜ˆå€¼: {growth_rate:.2f}% < {self.thresholds['knowledge_growth_rate_min'] * 100}%"
                    })

            # æ£€æŸ¥æœç´¢æˆåŠŸç‡
            if "search_performance" in self.current_metrics:
                success_rate = self.current_metrics["search_performance"].get("search_success_rate", 0)
                if success_rate < self.thresholds["search_success_rate_min"] * 100:
                    alerts.append({
                        "type": "warning",
                        "metric": "search_success_rate",
                        "current_value": success_rate,
                        "threshold": self.thresholds["search_success_rate_min"] * 100,
                        "message": f"æœç´¢æˆåŠŸç‡ä½äºé˜ˆå€¼: {success_rate:.2f}% < {self.thresholds['search_success_rate_min'] * 100}%"
                    })

            # æ£€æŸ¥æ¨èé‡‡çº³ç‡
            if "recommendations" in self.current_metrics:
                acceptance_rate = self.current_metrics["recommendations"].get("recommendation_acceptance_rate", 0)
                if acceptance_rate < self.thresholds["recommendation_acceptance_rate_min"] * 100:
                    alerts.append({
                        "type": "warning",
                        "metric": "recommendation_acceptance_rate",
                        "current_value": acceptance_rate,
                        "threshold": self.thresholds["recommendation_acceptance_rate_min"] * 100,
                        "message": f"æ¨èé‡‡çº³ç‡ä½äºé˜ˆå€¼: {acceptance_rate:.2f}% < {self.thresholds['recommendation_acceptance_rate_min'] * 100}%"
                    })

            # æ£€æŸ¥å¹³å‡å“åº”æ—¶é—´
            if "api_performance" in self.current_metrics:
                avg_time = self.current_metrics["api_performance"].get("avg_response_time", 0)
                if avg_time > self.thresholds["avg_query_time_max"]:
                    alerts.append({
                        "type": "warning",
                        "metric": "avg_response_time",
                        "current_value": avg_time,
                        "threshold": self.thresholds["avg_query_time_max"],
                        "message": f"å¹³å‡å“åº”æ—¶é—´è¶…è¿‡é˜ˆå€¼: {avg_time:.3f}s > {self.thresholds['avg_query_time_max']}s"
                    })

            # æ£€æŸ¥ç³»ç»Ÿå¯ç”¨æ€§
            if "system_health" in self.current_metrics:
                availability = self.current_metrics["system_health"].get("system_availability", 0)
                if availability < self.thresholds["system_availability_min"] * 100:
                    alerts.append({
                        "type": "critical",
                        "metric": "system_availability",
                        "current_value": availability,
                        "threshold": self.thresholds["system_availability_min"] * 100,
                        "message": f"ç³»ç»Ÿå¯ç”¨æ€§ä½äºé˜ˆå€¼: {availability:.2f}% < {self.thresholds['system_availability_min'] * 100}%"
                    })

        except Exception as e:
            logger.error(f"Failed to check threshold alerts: {e}")

        return alerts

    def save_metrics(self) -> bool:
        """ä¿å­˜æŒ‡æ ‡æ•°æ®"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            metrics_file = f"metrics_report_{timestamp}.json"

            with open(metrics_file, 'w', encoding='utf-8') as f:
                json.dump(self.current_metrics, f, indent=2, ensure_ascii=False)

            # åŒæ—¶ä¿å­˜åˆ°å†å²è®°å½•
            history_file = "metrics_history.json"
            try:
                with open(history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            except FileNotFoundError:
                history = []

            history.append({
                "timestamp": datetime.now().isoformat(),
                "metrics": self.current_metrics
            })

            # ä¿ç•™æœ€è¿‘100æ¡è®°å½•
            history = history[-100:]

            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)

            logger.info(f"Metrics saved to: {metrics_file}")
            logger.info(f"History updated in: {history_file}")
            return True

        except Exception as e:
            logger.error(f"Failed to save metrics: {e}")
            return False

    def generate_metrics_report(self) -> str:
        """ç”ŸæˆæŒ‡æ ‡æŠ¥å‘Š"""
        try:
            if not self.current_metrics:
                return "No metrics available"

            report = f"""
# çŸ¥è¯†åº“ç³»ç»ŸæŒ‡æ ‡æŠ¥å‘Š
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ğŸ¯ æ€»ä½“å¥åº·è¯„åˆ†
- **å¥åº·è¯„åˆ†**: {self.current_metrics.get('overall_health_score', 0)}/100
- **ç³»ç»ŸçŠ¶æ€**: {self.current_metrics.get('overall_status', 'unknown')}

## ğŸ“Š çŸ¥è¯†åº“å¢é•¿æŒ‡æ ‡
- **æ€»æ¡ç›®æ•°**: {self.current_metrics.get('knowledge_growth', {}).get('total_entries', 0)}
- **å‘¨å¢é•¿æ•°**: {self.current_metrics.get('knowledge_growth', {}).get('week_growth_count', 0)}
- **å‘¨å¢é•¿ç‡**: {self.current_metrics.get('knowledge_growth', {}).get('week_growth_rate', 0)}%
- **å¢é•¿çŠ¶æ€**: {self.current_metrics.get('knowledge_growth', {}).get('growth_status', 'unknown')}

## ğŸ” æœç´¢æ€§èƒ½æŒ‡æ ‡
- **æ€»æœç´¢æ¬¡æ•°**: {self.current_metrics.get('search_performance', {}).get('total_searches', 0)}
- **æœç´¢æˆåŠŸç‡**: {self.current_metrics.get('search_performance', {}).get('search_success_rate', 0)}%
- **å¹³å‡å“åº”æ—¶é—´**: {self.current_metrics.get('search_performance', {}).get('avg_response_time', 0)}s
- **æœç´¢çŠ¶æ€**: {self.current_metrics.get('search_performance', {}).get('search_status', 'unknown')}

## ğŸ’¡ æ¨èç³»ç»ŸæŒ‡æ ‡
- **æ€»æ¨èæ•°**: {self.current_metrics.get('recommendations', {}).get('total_recommendations', 0)}
- **å¹³å‡ç½®ä¿¡åº¦**: {self.current_metrics.get('recommendations', {}).get('avg_confidence_score', 0)}%
- **æ¨èé‡‡çº³ç‡**: {self.current_metrics.get('recommendations', {}).get('recommendation_acceptance_rate', 0)}%
- **æ¨èçŠ¶æ€**: {self.current_metrics.get('recommendations', {}).get('recommendation_status', 'unknown')}

## ğŸ¥ ç³»ç»Ÿå¥åº·æŒ‡æ ‡
- **æ•°æ®åº“è¿æ¥**: {'âœ… æ­£å¸¸' if self.current_metrics.get('system_health', {}).get('database_connected') else 'âŒ å¼‚å¸¸'}
- **æ•°æ®åº“å¤§å°**: {self.current_metrics.get('system_health', {}).get('database_size_mb', 0)} MB
- **ç³»ç»Ÿå¯ç”¨æ€§**: {self.current_metrics.get('system_health', {}).get('system_availability', 0)}%
- **ç³»ç»ŸçŠ¶æ€**: {self.current_metrics.get('system_health', {}).get('system_status', 'unknown')}

## ğŸ‘¥ ç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡
- **ä»Šæ—¥æ´»è·ƒç”¨æˆ·**: {self.current_metrics.get('user_engagement', {}).get('active_users_today', 0)}
- **å¹³å‡ä¼šè¯æ—¶é•¿**: {self.current_metrics.get('user_engagement', {}).get('avg_session_duration', 0)} åˆ†é’Ÿ
- **é‡å¤ç”¨æˆ·ç‡**: {self.current_metrics.get('user_engagement', {}).get('repeat_user_rate', 0)}%

## ğŸš€ APIæ€§èƒ½æŒ‡æ ‡
- **æ€»è¯·æ±‚æ•°**: {self.current_metrics.get('api_performance', {}).get('total_requests', 0)}
- **å¹³å‡å“åº”æ—¶é—´**: {self.current_metrics.get('api_performance', {}).get('avg_response_time', 0)}s
- **é”™è¯¯ç‡**: {self.current_metrics.get('api_performance', {}).get('overall_error_rate', 0)}%
- **APIçŠ¶æ€**: {self.current_metrics.get('api_performance', {}).get('api_status', 'unknown')}

## ğŸ’¼ ä¸šåŠ¡å½±å“æŒ‡æ ‡
- **æ¯å‘¨èŠ‚çœæ—¶é—´**: {self.current_metrics.get('business_impact', {}).get('time_saved_hours_per_week', 0)} å°æ—¶
- **ç”Ÿäº§åŠ›æå‡**: {self.current_metrics.get('business_impact', {}).get('productivity_improvement', 0)}%
- **çŸ¥è¯†å¤ç”¨ç‡**: {self.current_metrics.get('business_impact', {}).get('knowledge_reuse_rate', 0)}%

## ğŸš¨ å‘Šè­¦ä¿¡æ¯
"""
            alerts = self.current_metrics.get('alerts', [])
            if alerts:
                for alert in alerts:
                    report += f"- **{alert['type'].upper()}**: {alert['message']}\n"
            else:
                report += "- âœ… æ‰€æœ‰æŒ‡æ ‡å‡åœ¨æ­£å¸¸èŒƒå›´å†…\n"

            report += f"""
---
*æŠ¥å‘Šç”±æ™ºèƒ½çŸ¥è¯†åº“ç›‘æ§ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

            return report

        except Exception as e:
            logger.error(f"Failed to generate metrics report: {e}")
            return "Failed to generate report"

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.conn:
            self.conn.close()
            logger.info("Database connection closed")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ”¶é›†ç³»ç»ŸæŒ‡æ ‡")
    parser.add_argument("--mode", choices=["collect", "report", "check"], default="collect",
                       help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--db-path", default="knowledge_base.db", help="æ•°æ®åº“è·¯å¾„")
    parser.add_argument("--output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    logger.info("ğŸš€ Starting metrics collection...")

    # åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
    collector = MetricsCollector(args.db_path)

    try:
        # è¿æ¥æ•°æ®åº“
        if not collector.connect_database():
            sys.exit(1)

        if args.mode == "collect":
            # æ”¶é›†æŒ‡æ ‡
            metrics = collector.collect_all_metrics()

            # ä¿å­˜æŒ‡æ ‡
            collector.save_metrics()

            logger.info("âœ… Metrics collection completed successfully!")
            logger.info(f"Overall health score: {metrics.get('overall_health_score', 0)}")
            logger.info(f"System status: {metrics.get('overall_status', 'unknown')}")

        elif args.mode == "report":
            # ç”ŸæˆæŠ¥å‘Š
            collector.collect_all_metrics()
            report = collector.generate_metrics_report()

            if args.output:
                with open(args.output, 'w', encoding='utf-8') as f:
                    f.write(report)
                logger.info(f"ğŸ“„ Report saved to: {args.output}")
            else:
                print(report)

        elif args.mode == "check":
            # æ£€æŸ¥é˜ˆå€¼å‘Šè­¦
            collector.collect_all_metrics()
            alerts = collector.check_threshold_alerts()

            if alerts:
                logger.warning(f"âš ï¸  Found {len(alerts)} alerts:")
                for alert in alerts:
                    logger.warning(f"  - {alert['message']}")
            else:
                logger.info("âœ… All metrics within normal thresholds")

    finally:
        collector.close()

if __name__ == "__main__":
    main()