#!/usr/bin/env python3
"""
æ•°æ®æ¨¡å‹æ‰©å……è„šæœ¬
ä¸ºç°æœ‰æ•°æ®åº“è¡¨æ·»åŠ æ–°å­—æ®µå’Œç´¢å¼•
"""

import sqlite3
import logging
from datetime import datetime
from pathlib import Path

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger('ModelUpdater')

def backup_database(db_path: str, logger) -> str:
    """å¤‡ä»½æ•°æ®åº“"""
    import shutil
    from datetime import datetime

    backup_dir = Path("./data/backups")
    backup_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_file = backup_dir / f"db_before_model_update_{timestamp}.sqlite"

    try:
        shutil.copy2(db_path, backup_file)
        logger.info(f"âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_file}")
        return str(backup_file)
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
        return ""

def update_models(db_path: str = "./data/db.sqlite"):
    """æ›´æ–°æ•°æ®æ¨¡å‹"""
    logger = setup_logging()
    logger.info("ğŸš€ å¼€å§‹æ›´æ–°æ•°æ®æ¨¡å‹...")

    # å¤‡ä»½æ•°æ®åº“
    backup_file = backup_database(db_path, logger)
    if not backup_file:
        logger.error("âŒ å¤‡ä»½å¤±è´¥ï¼Œç»ˆæ­¢æ›´æ–°")
        return False

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # å¼€å¯äº‹åŠ¡
        cursor.execute("BEGIN TRANSACTION")

        # 1. æ›´æ–° Drawings è¡¨
        logger.info("ğŸ“ æ›´æ–° Drawings è¡¨...")

        # æ£€æŸ¥å­—æ®µæ˜¯å¦å·²å­˜åœ¨
        cursor.execute("PRAGMA table_info(drawings)")
        existing_columns = [row[1] for row in cursor.fetchall()]

        # æ·»åŠ æ–°å­—æ®µ
        new_drawing_fields = {
            'standard_or_custom': 'BOOLEAN DEFAULT 0',
            'data_source': 'TEXT DEFAULT "manual"',
            'is_classified': 'BOOLEAN DEFAULT 0',
            'classification_confidence': 'REAL DEFAULT 0.0',
            'classification_date': 'TEXT'
        }

        for field, field_def in new_drawing_fields.items():
            if field not in existing_columns:
                alter_sql = f"ALTER TABLE drawings ADD COLUMN {field} {field_def}"
                cursor.execute(alter_sql)
                logger.info(f"  âœ… æ·»åŠ å­—æ®µ: drawings.{field}")
            else:
                logger.info(f"  âš ï¸ å­—æ®µå·²å­˜åœ¨: drawings.{field}")

        # 2. æ›´æ–° Customers è¡¨
        logger.info("ğŸ“ æ›´æ–° Customers è¡¨...")

        cursor.execute("PRAGMA table_info(customers)")
        existing_columns = [row[1] for row in cursor.fetchall()]

        # æ·»åŠ æ–°å­—æ®µ
        new_customer_fields = {
            'customer_status': 'TEXT DEFAULT "potential"',
            'last_inquiry_date': 'TEXT',
            'customer_level': 'TEXT DEFAULT "normal"',
            'total_drawings': 'INTEGER DEFAULT 0',
            'first_contact_date': 'TEXT',
            'contact_frequency': 'INTEGER DEFAULT 0',
            'notes': 'TEXT'
        }

        for field, field_def in new_customer_fields.items():
            if field not in existing_columns:
                alter_sql = f"ALTER TABLE customers ADD COLUMN {field} {field_def}"
                cursor.execute(alter_sql)
                logger.info(f"  âœ… æ·»åŠ å­—æ®µ: customers.{field}")
            else:
                logger.info(f"  âš ï¸ å­—æ®µå·²å­˜åœ¨: customers.{field}")

        # 3. æ›´æ–° FactoryQuote è¡¨
        logger.info("ğŸ“ æ›´æ–° FactoryQuote è¡¨...")

        cursor.execute("PRAGMA table_info(factory_quotes)")
        existing_columns = [row[1] for row in cursor.fetchall()]

        # æ·»åŠ æ–°å­—æ®µ
        new_quote_fields = {
            'quote_month': 'TEXT',
            'quote_quarter': 'TEXT',
            'quote_year': 'INTEGER',
            'price_change_pct': 'REAL',
            'is_standard_pricing': 'BOOLEAN DEFAULT 0',
            'quote_source': 'TEXT DEFAULT "manual"',
            'valid_until': 'TEXT'
        }

        for field, field_def in new_quote_fields.items():
            if field not in existing_columns:
                alter_sql = f"ALTER TABLE factory_quotes ADD COLUMN {field} {field_def}"
                cursor.execute(alter_sql)
                logger.info(f"  âœ… æ·»åŠ å­—æ®µ: factory_quotes.{field}")
            else:
                logger.info(f"  âš ï¸ å­—æ®µå·²å­˜åœ¨: factory_quotes.{field}")

        # 4. æ›´æ–° Specifications è¡¨
        logger.info("ğŸ“ æ›´æ–° Specifications è¡¨...")

        cursor.execute("PRAGMA table_info(specifications)")
        existing_columns = [row[1] for row in cursor.fetchall()]

        # æ·»åŠ æ–°å­—æ®µ
        new_spec_fields = {
            'spec_source': 'TEXT DEFAULT "manual"',
            'last_updated': 'TEXT',
            'is_active': 'BOOLEAN DEFAULT 1',
            'spec_version': 'TEXT DEFAULT "1.0"',
            'supplier_id': 'INTEGER'
        }

        for field, field_def in new_spec_fields.items():
            if field not in existing_columns:
                alter_sql = f"ALTER TABLE specifications ADD COLUMN {field} {field_def}"
                cursor.execute(alter_sql)
                logger.info(f"  âœ… æ·»åŠ å­—æ®µ: specifications.{field}")
            else:
                logger.info(f"  âš ï¸ å­—æ®µå·²å­˜åœ¨: specifications.{field}")

        # 5. æ·»åŠ æ–°çš„ç´¢å¼•
        logger.info("ğŸ“Š åˆ›å»ºæ–°ç´¢å¼•...")

        new_indexes = [
            # Drawings è¡¨ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_drawings_standard_custom ON drawings(standard_or_custom)",
            "CREATE INDEX IF NOT EXISTS idx_drawings_data_source ON drawings(data_source)",
            "CREATE INDEX IF NOT EXISTS idx_drawings_is_classified ON drawings(is_classified)",
            "CREATE INDEX IF NOT EXISTS idx_drawings_classification_confidence ON drawings(classification_confidence)",
            "CREATE INDEX IF NOT EXISTS idx_drawings_classification_date ON drawings(classification_date)",
            "CREATE INDEX IF NOT EXISTS idx_drawings_category_classified ON drawings(product_category, is_classified)",

            # Customers è¡¨ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_customers_status ON customers(customer_status)",
            "CREATE INDEX IF NOT EXISTS idx_customers_last_inquiry ON customers(last_inquiry_date)",
            "CREATE INDEX IF NOT EXISTS idx_customers_level ON customers(customer_level)",
            "CREATE INDEX IF NOT EXISTS idx_customers_total_drawings ON customers(total_drawings)",
            "CREATE INDEX IF NOT EXISTS idx_customers_first_contact ON customers(first_contact_date)",
            "CREATE INDEX IF NOT EXISTS idx_customers_contact_frequency ON customers(contact_frequency)",
            "CREATE INDEX IF NOT EXISTS idx_customers_status_level ON customers(customer_status, customer_level)",

            # FactoryQuote è¡¨ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_quotes_quote_month ON factory_quotes(quote_month)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_quote_quarter ON factory_quotes(quote_quarter)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_quote_year ON factory_quotes(quote_year)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_price_change ON factory_quotes(price_change_pct)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_is_standard_pricing ON factory_quotes(is_standard_pricing)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_quote_source ON factory_quotes(quote_source)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_valid_until ON factory_quotes(valid_until)",
            "CREATE INDEX IF NOT EXISTS idx_quotes_factory_month_category ON factory_quotes(factory_id, quote_month, product_category)",

            # Specifications è¡¨ç´¢å¼•
            "CREATE INDEX IF NOT EXISTS idx_specifications_source ON specifications(spec_source)",
            "CREATE INDEX IF NOT EXISTS idx_specifications_last_updated ON specifications(last_updated)",
            "CREATE INDEX IF NOT EXISTS idx_specifications_is_active ON specifications(is_active)",
            "CREATE INDEX IF NOT EXISTS idx_specifications_version ON specifications(spec_version)",
            "CREATE INDEX IF NOT EXISTS idx_specifications_supplier ON specifications(supplier_id)"
        ]

        for index_sql in new_indexes:
            cursor.execute(index_sql)
            logger.info(f"  âœ… åˆ›å»ºç´¢å¼•: {index_sql.split('idx_')[1].split(' ')[0]}")

        # 6. åˆå§‹åŒ–æ•°æ®
        logger.info("ğŸ”„ åˆå§‹åŒ–æ–°å­—æ®µæ•°æ®...")

        # åˆå§‹åŒ–å®¢æˆ·ç»Ÿè®¡æ•°æ®
        cursor.execute("""
            UPDATE customers
            SET total_drawings = (
                SELECT COUNT(*)
                FROM drawings
                WHERE drawings.customer_id = customers.id
            )
        """)

        # åˆå§‹åŒ–æŠ¥ä»·æ—¶é—´å­—æ®µ
        cursor.execute("""
            UPDATE factory_quotes
            SET quote_month = substr(quote_date, 1, 7),
                quote_year = CAST(substr(quote_date, 1, 4) AS INTEGER),
                quote_quarter = CASE
                    WHEN CAST(substr(quote_date, 6, 2) AS INTEGER) IN (1,2,3) THEN 'Q1'
                    WHEN CAST(substr(quote_date, 6, 2) AS INTEGER) IN (4,5,6) THEN 'Q2'
                    WHEN CAST(substr(quote_date, 6, 2) AS INTEGER) IN (7,8,9) THEN 'Q3'
                    ELSE 'Q4'
                END
            WHERE quote_date IS NOT NULL
        """)

        # æäº¤äº‹åŠ¡
        conn.commit()
        logger.info("âœ… æ•°æ®æ¨¡å‹æ›´æ–°å®Œæˆ")

        # 7. éªŒè¯æ›´æ–°ç»“æœ
        logger.info("ğŸ” éªŒè¯æ›´æ–°ç»“æœ...")

        # æ£€æŸ¥è¡¨ç»“æ„
        for table_name in ['customers', 'drawings', 'factory_quotes', 'specifications']:
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            logger.info(f"  ğŸ“‹ {table_name}: {len(columns)} ä¸ªå­—æ®µ")

        # æ£€æŸ¥ç´¢å¼•æ•°é‡
        cursor.execute("""
            SELECT COUNT(*)
            FROM sqlite_master
            WHERE type='index' AND name NOT LIKE 'sqlite_%'
        """)
        index_count = cursor.fetchone()[0]
        logger.info(f"  ğŸ“Š æ€»ç´¢å¼•æ•°: {index_count}")

        conn.close()
        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ¨¡å‹æ›´æ–°å¤±è´¥: {e}")
        logger.error(f"ğŸ’¡ æ•°æ®åº“å¤‡ä»½ä½äº: {backup_file}")
        if 'conn' in locals():
            conn.rollback()
            conn.close()
        return False

def generate_migration_report(db_path: str):
    """ç”Ÿæˆè¿ç§»æŠ¥å‘Š"""
    logger = setup_logging()

    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # æ”¶é›†è¡¨ç»“æ„ä¿¡æ¯
        tables_info = {}
        for table_name in ['customers', 'drawings', 'factory_quotes', 'specifications']:
            cursor.execute(f"PRAGMA table_info({table_name})")
            columns = cursor.fetchall()
            tables_info[table_name] = [
                {
                    'name': col[1],
                    'type': col[2],
                    'not_null': bool(col[3]),
                    'default': col[4],
                    'primary_key': bool(col[5])
                }
                for col in columns
            ]

        # æ”¶é›†ç´¢å¼•ä¿¡æ¯
        cursor.execute("""
            SELECT name, tbl_name, sql
            FROM sqlite_master
            WHERE type='index' AND name NOT LIKE 'sqlite_%'
            ORDER BY tbl_name, name
        """)
        indexes = cursor.fetchall()

        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'migration_date': datetime.now().isoformat(),
            'database_path': db_path,
            'tables': tables_info,
            'indexes': [
                {
                    'name': idx[0],
                    'table': idx[1],
                    'sql': idx[2]
                }
                for idx in indexes
            ],
            'summary': {
                'total_tables': len(tables_info),
                'total_indexes': len(indexes)
            }
        }

        # ä¿å­˜æŠ¥å‘Š
        report_file = f"./data/processed/model_migration_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        Path("./data/processed").mkdir(exist_ok=True)

        with open(report_file, 'w', encoding='utf-8') as f:
            import json
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ“„ è¿ç§»æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        conn.close()
        return report_file

    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆè¿ç§»æŠ¥å‘Šå¤±è´¥: {e}")
        return ""

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='æ•°æ®æ¨¡å‹æ›´æ–°å·¥å…·')
    parser.add_argument('--db-path', default='./data/db.sqlite', help='æ•°æ®åº“æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--backup-only', action='store_true', help='ä»…å¤‡ä»½æ•°æ®åº“')
    parser.add_argument('--report-only', action='store_true', help='ä»…ç”ŸæˆæŠ¥å‘Š')

    args = parser.parse_args()

    if args.backup_only:
        logger = setup_logging()
        backup_file = backup_database(args.db_path, logger)
        if backup_file:
            print(f"âœ… å¤‡ä»½å®Œæˆ: {backup_file}")
        else:
            print("âŒ å¤‡ä»½å¤±è´¥")
    elif args.report_only:
        report_file = generate_migration_report(args.db_path)
        if report_file:
            print(f"âœ… æŠ¥å‘Šç”Ÿæˆå®Œæˆ: {report_file}")
        else:
            print("âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
    else:
        success = update_models(args.db_path)
        if success:
            report_file = generate_migration_report(args.db_path)
            print(f"âœ… æ•°æ®æ¨¡å‹æ›´æ–°å®Œæˆï¼")
            if report_file:
                print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        else:
            print("âŒ æ•°æ®æ¨¡å‹æ›´æ–°å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—")

if __name__ == "__main__":
    main()