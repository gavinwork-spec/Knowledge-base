#!/usr/bin/env python3
"""
åˆ†æå‡†å¤‡è„šæœ¬
ä¸ºåç»­ä¸šåŠ¡åˆ†æå’Œæé†’æœºåˆ¶å‡†å¤‡æ•°æ®å’Œåˆ†ææ¡†æ¶
"""

import sqlite3
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from models import DatabaseManager, Customer, Drawing, FactoryQuote, Factory

class AnalysisPreparation:
    """åˆ†æå‡†å¤‡å™¨"""

    def __init__(self, db_path: str = "./data/db.sqlite"):
        self.db_manager = DatabaseManager(db_path)
        self.export_dir = Path("./data/analysis")
        self.export_dir.mkdir(exist_ok=True)

    def prepare_quote_trend_analysis(self):
        """å‡†å¤‡æŠ¥ä»·è¶‹åŠ¿åˆ†æ"""
        print("ğŸ“ˆ å‡†å¤‡æŠ¥ä»·è¶‹åŠ¿åˆ†æ...")

        with self.db_manager:
            conn = self.db_manager.connect()

            # å¯¼å‡ºå·¥å‚æŠ¥ä»·æ•°æ®
            df_quotes = pd.read_sql_query("""
                SELECT
                    fq.id,
                    fq.factory_id,
                    f.factory_name,
                    fq.product_category,
                    fq.quote_date,
                    fq.price,
                    fq.moq,
                    fq.notes,
                    fq.created_at
                FROM factory_quotes fq
                LEFT JOIN factories f ON fq.factory_id = f.id
                ORDER BY fq.quote_date DESC, fq.product_category
            """, conn)

            if not df_quotes.empty:
                # æ·»åŠ åˆ†æå­—æ®µ
                df_quotes['quote_date'] = pd.to_datetime(df_quotes['quote_date'], format='ISO8601', errors='coerce')
                df_quotes['price_per_unit'] = df_quotes['price']
                df_quotes['quarter'] = df_quotes['quote_date'].dt.to_period('Q')
                df_quotes['month'] = df_quotes['quote_date'].dt.to_period('M')

                # å¯¼å‡ºåˆ†ææ•°æ®
                quotes_file = self.export_dir / "factory_quotes_analysis.csv"
                df_quotes.to_csv(quotes_file, index=False, encoding='utf-8')
                print(f"  âœ… æŠ¥ä»·æ•°æ®å·²å¯¼å‡º: {quotes_file}")

                # ç”Ÿæˆè¶‹åŠ¿åˆ†æ
                self._generate_quote_trends(df_quotes)

    def _generate_quote_trends(self, df_quotes):
        """ç”ŸæˆæŠ¥ä»·è¶‹åŠ¿åˆ†æ"""
        if df_quotes.empty:
            return

        print("  ğŸ“Š ç”ŸæˆæŠ¥ä»·è¶‹åŠ¿...")

        # æŒ‰äº§å“ç±»åˆ«çš„ä»·æ ¼è¶‹åŠ¿
        category_trends = df_quotes.groupby('product_category').agg({
            'price': ['mean', 'min', 'max', 'count'],
            'quote_date': ['min', 'max']
        }).round(2)

        category_file = self.export_dir / "price_trends_by_category.csv"
        category_trends.to_csv(category_file, encoding='utf-8')
        print(f"  âœ… åˆ†ç±»ä»·æ ¼è¶‹åŠ¿: {category_file}")

        # æŒ‰å·¥å‚çš„ä»·æ ¼åˆ†æ
        factory_trends = df_quotes.groupby('factory_name').agg({
            'price': ['mean', 'min', 'max', 'count'],
            'product_category': 'nunique'
        }).round(2)

        factory_file = self.export_dir / "price_trends_by_factory.csv"
        factory_trends.to_csv(factory_file, encoding='utf-8')
        print(f"  âœ… å·¥å‚ä»·æ ¼åˆ†æ: {factory_file}")

    def prepare_customer_analysis(self):
        """å‡†å¤‡å®¢æˆ·åˆ†æ"""
        print("ğŸ‘¥ å‡†å¤‡å®¢æˆ·åˆ†æ...")

        with self.db_manager:
            conn = self.db_manager.connect()

            # å®¢æˆ·æ´»è·ƒåº¦åˆ†æ
            df_customers = pd.read_sql_query("""
                SELECT
                    c.id,
                    c.company_name,
                    c.contact_email,
                    c.country,
                    c.language,
                    c.first_contact_date,
                    c.created_at,
                    COUNT(DISTINCT d.id) as drawing_count,
                    COUNT(DISTINCT d.product_category) as category_count,
                    MAX(d.upload_date) as last_drawing_date,
                    COUNT(DISTINCT ps.id) as process_count
                FROM customers c
                LEFT JOIN drawings d ON c.id = d.customer_id
                LEFT JOIN process_status ps ON c.id = ps.customer_id
                GROUP BY c.id
                ORDER BY c.company_name
            """, conn)

            if not df_customers.empty:
                # æ·»åŠ åˆ†æå­—æ®µ
                df_customers['first_contact_date'] = pd.to_datetime(df_customers['first_contact_date'], format='ISO8601', errors='coerce')
                df_customers['created_at'] = pd.to_datetime(df_customers['created_at'], format='ISO8601', errors='coerce')
                df_customers['last_drawing_date'] = pd.to_datetime(df_customers['last_drawing_date'], format='ISO8601', errors='coerce')

                # è®¡ç®—å®¢æˆ·æ´»è·ƒåº¦æŒ‡æ ‡
                today = datetime.now()
                df_customers['days_since_first_contact'] = (today - df_customers['first_contact_date']).dt.days
                df_customers['days_since_last_activity'] = (today - df_customers['last_drawing_date']).dt.days
                df_customers['activity_level'] = df_customers['drawing_count'].apply(self._classify_activity)

                customers_file = self.export_dir / "customer_analysis.csv"
                df_customers.to_csv(customers_file, index=False, encoding='utf-8')
                print(f"  âœ… å®¢æˆ·åˆ†ææ•°æ®: {customers_file}")

                # ç”Ÿæˆå®¢æˆ·ç»†åˆ†
                self._generate_customer_segments(df_customers)

    def _classify_activity(self, drawing_count):
        """åˆ†ç±»å®¢æˆ·æ´»è·ƒåº¦"""
        if drawing_count == 0:
            return "æœªæ´»è·ƒ"
        elif drawing_count <= 5:
            return "ä½æ´»è·ƒ"
        elif drawing_count <= 20:
            return "ä¸­æ´»è·ƒ"
        else:
            return "é«˜æ´»è·ƒ"

    def _generate_customer_segments(self, df_customers):
        """ç”Ÿæˆå®¢æˆ·ç»†åˆ†"""
        if df_customers.empty:
            return

        print("  ğŸ¯ ç”Ÿæˆå®¢æˆ·ç»†åˆ†...")

        # æŒ‰å›½å®¶å’Œæ´»è·ƒåº¦ç»†åˆ†
        segments = df_customers.groupby(['country', 'activity_level']).agg({
            'company_name': 'count',
            'drawing_count': 'sum',
            'category_count': 'sum'
        }).rename(columns={'company_name': 'customer_count'})

        segments_file = self.export_dir / "customer_segments.csv"
        segments.to_csv(segments_file, encoding='utf-8')
        print(f"  âœ… å®¢æˆ·ç»†åˆ†æ•°æ®: {segments_file}")

    def prepare_drawing_analysis(self):
        """å‡†å¤‡å›¾çº¸åˆ†æ"""
        print("ğŸ“„ å‡†å¤‡å›¾çº¸åˆ†æ...")

        with self.db_manager:
            conn = self.db_manager.connect()

            # å›¾çº¸æ´»è·ƒåº¦åˆ†æ
            df_drawings = pd.read_sql_query("""
                SELECT
                    d.id,
                    d.drawing_name,
                    d.product_category,
                    d.status,
                    d.upload_date,
                    d.created_at,
                    c.company_name,
                    c.country,
                    d.notes
                FROM drawings d
                LEFT JOIN customers c ON d.customer_id = c.id
                ORDER BY d.upload_date DESC
            """, conn)

            if not df_drawings.empty:
                # æ—¶é—´åˆ†æ
                df_drawings['upload_date'] = pd.to_datetime(df_drawings['upload_date'], format='ISO8601', errors='coerce')
                df_drawings['created_at'] = pd.to_datetime(df_drawings['created_at'], format='ISO8601', errors='coerce')
                df_drawings['month'] = df_drawings['upload_date'].dt.to_period('M')
                df_drawings['day_of_week'] = df_drawings['upload_date'].dt.day_name()

                drawings_file = self.export_dir / "drawing_analysis.csv"
                df_drawings.to_csv(drawings_file, index=False, encoding='utf-8')
                print(f"  âœ… å›¾çº¸åˆ†ææ•°æ®: {drawings_file}")

                # ç”Ÿæˆæœˆåº¦è¶‹åŠ¿
                self._generate_drawing_trends(df_drawings)

    def _generate_drawing_trends(self, df_drawings):
        """ç”Ÿæˆå›¾çº¸è¶‹åŠ¿"""
        if df_drawings.empty:
            return

        print("  ğŸ“ˆ ç”Ÿæˆå›¾çº¸è¶‹åŠ¿...")

        # æœˆåº¦ä¸Šä¼ è¶‹åŠ¿
        monthly_trends = df_drawings.groupby('month').agg({
            'id': 'count',
            'product_category': 'nunique',
            'company_name': 'nunique'
        }).rename(columns={'id': 'drawing_count'})

        monthly_file = self.export_dir / "drawing_monthly_trends.csv"
        monthly_trends.to_csv(monthly_file, encoding='utf-8')
        print(f"  âœ… æœˆåº¦è¶‹åŠ¿æ•°æ®: {monthly_file}")

        # æŒ‰ç±»åˆ«çš„ç»Ÿè®¡
        category_stats = df_drawings.groupby('product_category').agg({
            'id': 'count',
            'company_name': 'nunique',
            'status': lambda x: (x == 'pending').sum()
        }).rename(columns={'id': 'total_count', 'status': 'pending_count'})

        category_file = self.export_dir / "drawing_category_stats.csv"
        category_stats.to_csv(category_file, encoding='utf-8')
        print(f"  âœ… ç±»åˆ«ç»Ÿè®¡æ•°æ®: {category_file}")

    def prepare_factory_performance(self):
        """å‡†å¤‡å·¥å‚ç»©æ•ˆåˆ†æ"""
        print("ğŸ­ å‡†å¤‡å·¥å‚ç»©æ•ˆåˆ†æ...")

        with self.db_manager:
            conn = self.db_manager.connect()

            # å·¥å‚æŠ¥ä»·åˆ†æ
            df_factory = pd.read_sql_query("""
                SELECT
                    f.id,
                    f.factory_name,
                    f.location,
                    f.capability,
                    f.cost_reference,
                    f.production_cycle,
                    COUNT(fq.id) as quote_count,
                    AVG(fq.price) as avg_price,
                    MIN(fq.price) as min_price,
                    MAX(fq.price) as max_price,
                    AVG(fq.moq) as avg_moq,
                    COUNT(DISTINCT fq.product_category) as category_count
                FROM factories f
                LEFT JOIN factory_quotes fq ON f.id = fq.factory_id
                GROUP BY f.id
                ORDER BY quote_count DESC, avg_price
            """, conn)

            if not df_factory.empty:
                factory_file = self.export_dir / "factory_performance.csv"
                df_factory.to_csv(factory_file, index=False, encoding='utf-8')
                print(f"  âœ… å·¥å‚ç»©æ•ˆæ•°æ®: {factory_file}")

    def prepare_alert_metrics(self):
        """å‡†å¤‡æé†’æŒ‡æ ‡"""
        print("ğŸ”” å‡†å¤‡æé†’æŒ‡æ ‡...")

        with self.db_manager:
            conn = self.db_manager.connect()

            alerts = []

            # 1. é•¿æœŸæœªæ´»è·ƒå®¢æˆ·
            df_inactive = pd.read_sql_query("""
                SELECT
                    c.id as customer_id,
                    c.company_name,
                    c.contact_email,
                    c.country,
                    MAX(d.upload_date) as last_activity,
                    COUNT(DISTINCT d.id) as total_drawings
                FROM customers c
                LEFT JOIN drawings d ON c.id = d.customer_id
                GROUP BY c.id
                HAVING last_activity < date('now', '-30 days') OR last_activity IS NULL
            """, conn)

            if not df_inactive.empty:
                for _, row in df_inactive.iterrows():
                    alerts.append({
                        'type': 'inactive_customer',
                        'customer_id': row['customer_id'],
                        'company_name': row['company_name'],
                        'email': row['contact_email'],
                        'severity': 'medium',
                        'message': f"å®¢æˆ· {row['company_name']} é•¿æœŸæœªæ´»è·ƒ",
                        'days_inactive': 30,
                        'data': row.to_dict()
                    })

            # 2. æœªåˆ†ç±»å›¾çº¸è¿‡å¤š
            unclassified_count = pd.read_sql_query("""
                SELECT COUNT(*) as count
                FROM drawings
                WHERE product_category = 'æœªåˆ†ç±»'
            """, conn).iloc[0]['count']

            if unclassified_count > 100:
                alerts.append({
                    'type': 'unclassified_drawings',
                    'severity': 'high',
                    'message': f"æœªåˆ†ç±»å›¾çº¸è¿‡å¤š: {unclassified_count} ä¸ª",
                    'count': unclassified_count,
                    'threshold': 100
                })

            # 3. æŠ¥ä»·æ³¢åŠ¨æ£€æµ‹ (å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶)
            quote_analysis = pd.read_sql_query("""
                SELECT
                    product_category,
                    AVG(price) as avg_price,
                    COUNT(*) as quote_count
                FROM factory_quotes
                WHERE quote_date >= date('now', '-90 days')
                GROUP BY product_category
                HAVING quote_count >= 3
            """, conn)

            if not quote_analysis.empty:
                # ä¸å†å²ä»·æ ¼æ¯”è¾ƒ
                historical = pd.read_sql_query("""
                    SELECT
                        product_category,
                        AVG(price) as historical_avg
                    FROM factory_quotes
                    WHERE quote_date < date('now', '-90 days')
                    GROUP BY product_category
                """, conn)

                for _, recent in quote_analysis.iterrows():
                    historical_match = historical[historical['product_category'] == recent['product_category']]
                    if not historical_match.empty:
                        hist_avg = historical_match.iloc[0]['historical_avg']
                        price_change = (recent['avg_price'] - hist_avg) / hist_avg * 100

                        if abs(price_change) > 10:  # 10% å˜åŒ–é˜ˆå€¼
                            alerts.append({
                                'type': 'price_fluctuation',
                                'product_category': recent['product_category'],
                                'severity': 'high' if abs(price_change) > 20 else 'medium',
                                'message': f"{recent['product_category']} ä»·æ ¼æ³¢åŠ¨ {price_change:.1f}%",
                                'recent_avg': recent['avg_price'],
                                'historical_avg': hist_avg,
                                'change_percent': price_change
                            })

            # å¯¼å‡ºæé†’æ•°æ®
            if alerts:
                alerts_df = pd.DataFrame(alerts)
                alerts_file = self.export_dir / "current_alerts.csv"
                alerts_df.to_csv(alerts_file, index=False, encoding='utf-8')
                print(f"  âœ… å½“å‰æé†’: {alerts_file} ({len(alerts)} ä¸ªæé†’)")
            else:
                print("  âœ… å½“å‰æ— è§¦å‘æé†’")

    def generate_analysis_summary(self):
        """ç”Ÿæˆåˆ†ææ‘˜è¦"""
        print("ğŸ“‹ ç”Ÿæˆåˆ†ææ‘˜è¦...")

        summary_file = self.export_dir / f"analysis_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"

        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write("çŸ¥è¯†åº“åˆ†æå‡†å¤‡æ‘˜è¦\n")
            f.write("=" * 50 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            # åŸºç¡€ç»Ÿè®¡
            with self.db_manager:
                conn = self.db_manager.connect()
                cursor = conn.cursor()

                tables = ['customers', 'drawings', 'factories', 'factory_quotes']
                for table in tables:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    count = cursor.fetchone()[0]
                    f.write(f"{table}: {count} æ¡è®°å½•\n")

            f.write(f"\nå¯¼å‡ºæ–‡ä»¶ä½ç½®: {self.export_dir}\n")

            # åˆ—å‡ºå¯¼å‡ºçš„æ–‡ä»¶
            analysis_files = list(self.export_dir.glob("*.csv"))
            if analysis_files:
                f.write(f"\nå¯¼å‡ºçš„åˆ†ææ–‡ä»¶:\n")
                for file_path in sorted(analysis_files):
                    f.write(f"- {file_path.name}\n")

        print(f"  âœ… åˆ†ææ‘˜è¦: {summary_file}")

    def run_full_preparation(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†æå‡†å¤‡"""
        print("ğŸš€ å¼€å§‹åˆ†ææ•°æ®å‡†å¤‡...")
        print("=" * 60)

        try:
            self.prepare_quote_trend_analysis()
            self.prepare_customer_analysis()
            self.prepare_drawing_analysis()
            self.prepare_factory_performance()
            self.prepare_alert_metrics()
            self.generate_analysis_summary()

            print("\n" + "=" * 60)
            print("âœ… åˆ†ææ•°æ®å‡†å¤‡å®Œæˆ!")
            print(f"ğŸ“ å¯¼å‡ºç›®å½•: {self.export_dir}")
            print("=" * 60)

        except Exception as e:
            print(f"âŒ åˆ†æå‡†å¤‡å¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    analyzer = AnalysisPreparation()
    analyzer.run_full_preparation()

if __name__ == "__main__":
    main()