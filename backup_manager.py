#!/usr/bin/env python3
"""
å¤‡ä»½ç®¡ç†è„šæœ¬
æä¾›è‡ªåŠ¨å¤‡ä»½ã€ç‰ˆæœ¬æ§åˆ¶å’Œæ¢å¤åŠŸèƒ½
"""

import os
import shutil
import sqlite3
import json
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
import logging
import gzip
from typing import Dict

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨"""

    def __init__(self, project_path: str = "./"):
        self.project_path = Path(project_path).resolve()
        self.db_path = self.project_path / "data" / "db.sqlite"
        self.backup_dir = self.project_path / "data" / "backups"
        self.setup_logging()

    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_dir = self.project_path / "logs"
        log_dir.mkdir(exist_ok=True)

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_dir / 'backup.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('BackupManager')

    def create_database_backup(self, backup_type: str = "manual") -> str:
        """åˆ›å»ºæ•°æ®åº“å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"db_backup_{backup_type}_{timestamp}.sqlite"

        try:
            if self.db_path.exists():
                shutil.copy2(self.db_path, backup_file)
                self.logger.info(f"âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_file}")
                return str(backup_file)
            else:
                self.logger.warning("âš ï¸ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨")
                return ""

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            return ""

    def create_compressed_backup(self) -> str:
        """åˆ›å»ºå‹ç¼©å¤‡ä»½"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_file = self.backup_dir / f"project_backup_{timestamp}.tar.gz"

        try:
            # ä½¿ç”¨taråˆ›å»ºå‹ç¼©å¤‡ä»½
            cmd = [
                'tar', '-czf', str(backup_file),
                '--exclude', '.git',
                '--exclude', 'logs',
                '--exclude', 'data/processed',
                '--exclude', 'data/failed',
                '--exclude', '__pycache__',
                '--exclude', '*.pyc',
                '--exclude', 'data/backups',
                '.'
            ]

            result = subprocess.run(cmd, cwd=self.project_path, capture_output=True, text=True)

            if result.returncode == 0:
                self.logger.info(f"âœ… å‹ç¼©å¤‡ä»½å®Œæˆ: {backup_file}")
                return str(backup_file)
            else:
                self.logger.error(f"âŒ å‹ç¼©å¤‡ä»½å¤±è´¥: {result.stderr}")
                return ""

        except Exception as e:
            self.logger.error(f"âŒ å‹ç¼©å¤‡ä»½å¤±è´¥: {e}")
            return ""

    def create_git_snapshot(self, message: str = None) -> bool:
        """åˆ›å»ºGitå¿«ç…§"""
        try:
            os.chdir(self.project_path)

            # æ£€æŸ¥æ˜¯å¦æœ‰Gitä»“åº“
            if not (self.project_path / ".git").exists():
                self.logger.warning("âš ï¸ Gitä»“åº“ä¸å­˜åœ¨ï¼Œè·³è¿‡Gitå¿«ç…§")
                return False

            # æ·»åŠ æ‰€æœ‰æ›´æ”¹
            subprocess.run(['git', 'add', '.'], check=True, capture_output=True)

            # åˆ›å»ºæäº¤
            if message is None:
                message = f"è‡ªåŠ¨å¤‡ä»½å¿«ç…§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

            result = subprocess.run(['git', 'commit', '-m', message],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                self.logger.info(f"âœ… Gitå¿«ç…§å®Œæˆ: {message}")
                return True
            else:
                self.logger.warning(f"âš ï¸ Gitå¿«ç…§æ— æ›´æ”¹æˆ–å¤±è´¥: {result.stderr}")
                return False

        except subprocess.CalledProcessError as e:
            self.logger.error(f"âŒ Gitå¿«ç…§å¤±è´¥: {e}")
            return False
        except Exception as e:
            self.logger.error(f"âŒ Gitå¿«ç…§å¼‚å¸¸: {e}")
            return False

    def cleanup_old_backups(self, days_to_keep: int = 30) -> Dict[str, int]:
        """æ¸…ç†æ—§å¤‡ä»½"""
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)

        stats = {
            'deleted_db_backups': 0,
            'deleted_compressed_backups': 0,
            'freed_space_mb': 0
        }

        try:
            # æ¸…ç†æ•°æ®åº“å¤‡ä»½
            for backup_file in self.backup_dir.glob("db_backup_*.sqlite"):
                if backup_file.stat().st_mtime < cutoff_date.timestamp():
                    file_size = backup_file.stat().st_size / (1024 * 1024)  # MB
                    backup_file.unlink()
                    stats['deleted_db_backups'] += 1
                    stats['freed_space_mb'] += file_size
                    self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½: {backup_file.name}")

            # æ¸…ç†å‹ç¼©å¤‡ä»½
            for backup_file in self.backup_dir.glob("project_backup_*.tar.gz"):
                if backup_file.stat().st_mtime < cutoff_date.timestamp():
                    file_size = backup_file.stat().st_size / (1024 * 1024)  # MB
                    backup_file.unlink()
                    stats['deleted_compressed_backups'] += 1
                    stats['freed_space_mb'] += file_size
                    self.logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§å‹ç¼©å¤‡ä»½: {backup_file.name}")

            self.logger.info(f"âœ… å¤‡ä»½æ¸…ç†å®Œæˆï¼Œé‡Šæ”¾ç©ºé—´: {stats['freed_space_mb']:.1f} MB")
            return stats

        except Exception as e:
            self.logger.error(f"âŒ å¤‡ä»½æ¸…ç†å¤±è´¥: {e}")
            return stats

    def list_backups(self) -> Dict[str, list]:
        """åˆ—å‡ºæ‰€æœ‰å¤‡ä»½"""
        backups = {
            'database_backups': [],
            'compressed_backups': []
        }

        try:
            # æ•°æ®åº“å¤‡ä»½
            for backup_file in sorted(self.backup_dir.glob("db_backup_*.sqlite"),
                                    key=lambda x: x.stat().st_mtime, reverse=True):
                backups['database_backups'].append({
                    'name': backup_file.name,
                    'path': str(backup_file),
                    'size_mb': backup_file.stat().st_size / (1024 * 1024),
                    'created_date': datetime.fromtimestamp(backup_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                })

            # å‹ç¼©å¤‡ä»½
            for backup_file in sorted(self.backup_dir.glob("project_backup_*.tar.gz"),
                                    key=lambda x: x.stat().st_mtime, reverse=True):
                backups['compressed_backups'].append({
                    'name': backup_file.name,
                    'path': str(backup_file),
                    'size_mb': backup_file.stat().st_size / (1024 * 1024),
                    'created_date': datetime.fromtimestamp(backup_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                })

        except Exception as e:
            self.logger.error(f"âŒ åˆ—å‡ºå¤‡ä»½å¤±è´¥: {e}")

        return backups

    def restore_database(self, backup_file: str) -> bool:
        """æ¢å¤æ•°æ®åº“"""
        backup_path = Path(backup_file)

        if not backup_path.exists():
            self.logger.error(f"âŒ å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
            return False

        try:
            # åˆ›å»ºå½“å‰æ•°æ®åº“çš„å¤‡ä»½
            current_backup = self.create_database_backup("before_restore")
            if current_backup:
                self.logger.info(f"âœ… å½“å‰æ•°æ®åº“å·²å¤‡ä»½: {current_backup}")

            # æ¢å¤æ•°æ®åº“
            shutil.copy2(backup_path, self.db_path)
            self.logger.info(f"âœ… æ•°æ®åº“æ¢å¤å®Œæˆ: {backup_file}")

            # éªŒè¯æ¢å¤çš„æ•°æ®åº“
            if self.verify_database():
                self.logger.info("âœ… æ•°æ®åº“éªŒè¯é€šè¿‡")
                return True
            else:
                self.logger.error("âŒ æ•°æ®åº“éªŒè¯å¤±è´¥")
                return False

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {e}")
            return False

    def verify_database(self) -> bool:
        """éªŒè¯æ•°æ®åº“å®Œæ•´æ€§"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # æ£€æŸ¥å®Œæ•´æ€§
            cursor.execute("PRAGMA integrity_check")
            result = cursor.fetchone()

            if result[0] == "ok":
                # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
                cursor.execute("""
                    SELECT name FROM sqlite_master
                    WHERE type='table' AND name NOT LIKE 'sqlite_%'
                """)
                tables = [row[0] for row in cursor.fetchall()]

                expected_tables = ['customers', 'drawings', 'factories', 'factory_quotes', 'specifications', 'process_status']
                missing_tables = set(expected_tables) - set(tables)

                if missing_tables:
                    self.logger.error(f"âŒ ç¼ºå¤±è¡¨: {missing_tables}")
                    return False

                conn.close()
                return True
            else:
                self.logger.error(f"âŒ æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {result[0]}")
                return False

        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®åº“éªŒè¯å¤±è´¥: {e}")
            return False

    def backup_metadata(self, backup_type: str = "manual") -> Dict[str, any]:
        """å¤‡ä»½å…ƒæ•°æ®ä¿¡æ¯"""
        try:
            metadata = {
                'backup_time': datetime.now().isoformat(),
                'backup_type': backup_type,
                'database_size_mb': self.db_path.stat().st_size / (1024 * 1024) if self.db_path.exists() else 0,
                'project_path': str(self.project_path),
                'git_status': self.get_git_status(),
                'database_stats': self.get_database_stats()
            }

            # ä¿å­˜å…ƒæ•°æ®
            metadata_file = self.backup_dir / f"backup_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            return metadata

        except Exception as e:
            self.logger.error(f"âŒ å¤‡ä»½å…ƒæ•°æ®å¤±è´¥: {e}")
            return {}

    def get_git_status(self) -> Dict[str, any]:
        """è·å–GitçŠ¶æ€"""
        try:
            os.chdir(self.project_path)

            # æ£€æŸ¥æ˜¯å¦æœ‰æœªæäº¤çš„æ›´æ”¹
            result = subprocess.run(['git', 'status', '--porcelain'],
                                  capture_output=True, text=True)

            if result.returncode == 0:
                changed_files = len(result.stdout.strip().split('\n')) if result.stdout.strip() else 0
                return {
                    'has_uncommitted_changes': changed_files > 0,
                    'changed_files_count': changed_files
                }
            else:
                return {'error': 'Git status failed'}

        except Exception as e:
            return {'error': str(e)}

    def get_database_stats(self) -> Dict[str, int]:
        """è·å–æ•°æ®åº“ç»Ÿè®¡"""
        if not self.db_path.exists():
            return {}

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            stats = {}
            tables = ['customers', 'drawings', 'factories', 'factory_quotes', 'specifications', 'process_status']

            for table in tables:
                try:
                    cursor.execute(f"SELECT COUNT(*) FROM {table}")
                    stats[table] = cursor.fetchone()[0]
                except:
                    stats[table] = 0

            conn.close()
            return stats

        except Exception:
            return {}

    def run_full_backup(self, message: str = None) -> Dict[str, str]:
        """è¿è¡Œå®Œæ•´å¤‡ä»½æµç¨‹"""
        self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´å¤‡ä»½æµç¨‹...")

        results = {
            'database_backup': '',
            'compressed_backup': '',
            'git_snapshot': '',
            'metadata': ''
        }

        # 1. æ•°æ®åº“å¤‡ä»½
        db_backup = self.create_database_backup("scheduled")
        results['database_backup'] = db_backup

        # 2. Gitå¿«ç…§
        git_success = self.create_git_snapshot(message)
        results['git_snapshot'] = 'success' if git_success else 'failed'

        # 3. å‹ç¼©å¤‡ä»½
        compressed_backup = self.create_compressed_backup()
        results['compressed_backup'] = compressed_backup

        # 4. å¤‡ä»½å…ƒæ•°æ®
        metadata = self.backup_metadata("scheduled")
        results['metadata'] = 'success' if metadata else 'failed'

        # 5. æ¸…ç†æ—§å¤‡ä»½
        cleanup_stats = self.cleanup_old_backups()
        results['cleanup'] = f"åˆ é™¤ {cleanup_stats['deleted_db_backups']} ä¸ªDBå¤‡ä»½, {cleanup_stats['deleted_compressed_backups']} ä¸ªå‹ç¼©å¤‡ä»½"

        self.logger.info("âœ… å®Œæ•´å¤‡ä»½æµç¨‹å®Œæˆ")
        return results

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='å¤‡ä»½ç®¡ç†å·¥å…·')
    parser.add_argument('--type', choices=['db', 'compressed', 'git', 'full'],
                       default='full', help='å¤‡ä»½ç±»å‹')
    parser.add_argument('--message', help='Gitæäº¤æ¶ˆæ¯')
    parser.add_argument('--list', action='store_true', help='åˆ—å‡ºå¤‡ä»½')
    parser.add_argument('--cleanup', type=int, help='æ¸…ç†Nå¤©å‰çš„å¤‡ä»½')
    parser.add_argument('--restore', help='æ¢å¤æ•°æ®åº“å¤‡ä»½')

    args = parser.parse_args()

    manager = BackupManager()

    if args.list:
        backups = manager.list_backups()
        print("ğŸ“‹ æ•°æ®åº“å¤‡ä»½:")
        for backup in backups['database_backups'][:5]:
            print(f"  {backup['created_date']} - {backup['name']} ({backup['size_mb']:.1f} MB)")

        print("\nğŸ“¦ å‹ç¼©å¤‡ä»½:")
        for backup in backups['compressed_backups'][:3]:
            print(f"  {backup['created_date']} - {backup['name']} ({backup['size_mb']:.1f} MB)")

    elif args.restore:
        success = manager.restore_database(args.restore)
        if success:
            print("âœ… æ•°æ®åº“æ¢å¤æˆåŠŸ")
        else:
            print("âŒ æ•°æ®åº“æ¢å¤å¤±è´¥")

    elif args.cleanup:
        stats = manager.cleanup_old_backups(args.cleanup)
        print(f"âœ… æ¸…ç†å®Œæˆ: åˆ é™¤ {stats['deleted_db_backups']} ä¸ªDBå¤‡ä»½, "
              f"{stats['deleted_compressed_backups']} ä¸ªå‹ç¼©å¤‡ä»½, "
              f"é‡Šæ”¾ {stats['freed_space_mb']:.1f} MB ç©ºé—´")

    else:
        if args.type == 'db':
            manager.create_database_backup()
        elif args.type == 'compressed':
            manager.create_compressed_backup()
        elif args.type == 'git':
            manager.create_git_snapshot(args.message)
        else:  # full
            results = manager.run_full_backup(args.message)
            print("âœ… å®Œæ•´å¤‡ä»½å®Œæˆ:")
            for backup_type, result in results.items():
                print(f"  {backup_type}: {result}")

if __name__ == "__main__":
    main()